{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c40e977-8cf8-49b5-805c-e1ac1110a8cc",
   "metadata": {},
   "source": [
    "# A Practical Guide to Building a Seq2Seq Transformer from scratch with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1da560-8eed-4a96-a97c-7aecc57bff6e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f43e528-92db-41c9-b8b0-8f8f9092214b",
   "metadata": {},
   "source": [
    "This jupyter notebook details how to build a **sequence-to-sequence** (Seq2Seq) model using **PyTorch**, focusing on the **Transformer** architecture. Our goal is to develop a transpiler that translates and transpiles PL/I code into Kotlin. Throughout the notebook, weâ€™ll cover everything from setting up the necessary libraries to training the model and evaluating its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6692af6-f6dc-486a-b369-7918d54a74cf",
   "metadata": {},
   "source": [
    "## Libraries and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b3233-744a-4e32-8b62-6d1010689fd9",
   "metadata": {},
   "source": [
    "We start by installing the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39b85a-ad6e-461a-9220-4c96dcca837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2\n",
    "!pip install torchtext==0.8.1\n",
    "!pip install antlr4-python3-runtime==4.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa76569-0e4e-4ede-b67f-ee5a3b2408b5",
   "metadata": {},
   "source": [
    "We then import all the necessary libraries. **json** will be used to import our data, **antlr4** provides the backbone for our transpiler, enabling us to parse PL/I code and manipulate its structure with ease, **torch** PyTorch empowers us to build and train neural networks seamlessly, **torchtext** complements PyTorch by providing utilities for text processing and dataset handling, **jinja2** simplifies code generation with its template engine ensuring a smooth transition between languages and to finish **matplotlib** will come in handy during training for visualising our progress  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa9b17b-24bf-4cb8-860c-fb1ed8bb988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from antlr4 import *\n",
    "from pli.PLILexer import PLILexer\n",
    "from pli.PLIParser import PLIParser\n",
    "from pli.PLIVisitor import PLIVisitor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from jinja2 import Template\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c450d3e-f442-45f2-bfe1-d3512e6b61ec",
   "metadata": {},
   "source": [
    "## The Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1871b9-794a-4243-813f-dc90d1576328",
   "metadata": {},
   "source": [
    "The Transformer class encapsulates a custom implementation of the Transformer model, a powerful architecture for **sequence-to-sequence** tasks. It comprises various components, including **embedding layers** for source and target sequences, **positional embeddings** to capture sequence order, and a multi-layer Transformer module. The model utilizes **dropout** for regularization and employs **masks** to handle padding and prevent information leakage during training. With these components, the Transformer class can efficiently process source and target sequences, facilitating tasks like language translation or code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a751df-600d-4f8a-addf-a8e9ddda6cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    # Initialises the Transformer model\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_size,\n",
    "            src_vocab_size,\n",
    "            trg_vocab_size,\n",
    "            src_pad_idx,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_len,\n",
    "            device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    # Generates a mask for the source sequence to handle padding\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "\n",
    "        # (N, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    # Forward pass of the Transformer model\n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "                .unsqueeze(1)\n",
    "                .expand(src_seq_length, N)\n",
    "                .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "                .unsqueeze(1)\n",
    "                .expand(trg_seq_length, N)\n",
    "                .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        )\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f95555c-514a-4ba7-a729-e7c5c88edb11",
   "metadata": {},
   "source": [
    "## Data preparation and tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda324e-d084-4e90-8a74-b575e01937d9",
   "metadata": {},
   "source": [
    "For our model to understand and generate text, we need to tokenize our input data. We also set up our datasets to allow us to manage training and testing data efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ea9c3-0261-427e-99a3-2b293a694685",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b8c6d-5dfb-4b20-a80b-95309cf8a8dc",
   "metadata": {},
   "source": [
    "We define a simple **tokenizer** that splits a string into tokens based on whitespace, it then creates two **Field** objects with some specifications and finally we create a dictionary that maps field names to tuples to be used later to specify how to load and process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c127116-54cb-4570-84cc-73ebb591f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext.data as data\n",
    "\n",
    "tokenizer = lambda x: x.split()\n",
    "\n",
    "pli = data.Field(sequential=True, use_vocab=True, tokenize=tokenizer, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "ktl = data.Field(sequential=True, use_vocab=True, tokenize=tokenizer, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "fields = {'pli': ('p', pli), 'ktl': ('k', ktl)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161956e-fb38-484e-a7ea-1ce7e074183d",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb0945-e0d9-4a1d-be24-969287dc3c59",
   "metadata": {},
   "source": [
    "We're using the TabularDataset module from the torchtext.data package to create separate datasets for **training** and **testing**. The data is loaded from JSON files located in the 'data' directory. We specify the format of the data as JSON and define the fields to be extracted from the JSON files using the fields parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf949e1f-8a60-401d-9f6e-8f81c9e4d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.TabularDataset.splits(\n",
    "    path='data',\n",
    "    train='train.json',\n",
    "    test='test.json',\n",
    "    format='json',\n",
    "    fields=fields,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304ce06-4410-4b99-bbe0-1e1bed3f96a9",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0f545-05a7-4800-a9cc-8fb0cc090ed4",
   "metadata": {},
   "source": [
    "Building a vocabulary involves creating a dictionary that maps each unique word in the dataset to a unique index. This process is crucial for natural language processing tasks as it allows machine learning models to represent words as numerical values, which they can process and understand. In this case, we're building vocabularies for the PL/I (pli) and Kotlin (ktl) datasets, ensuring that the model has a predefined set of words it can understand and process during training and inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eceab04-1930-4cf2-bb98-1fb58e9e4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pli.build_vocab(train, max_size=10000, min_freq=1)\n",
    "ktl.build_vocab(train, max_size=10000, min_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e532d63-c3ab-4482-8819-a4bf41e442e7",
   "metadata": {},
   "source": [
    "## Translate and transpile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63006ee-e498-43b8-ad3a-0a087e687ac5",
   "metadata": {},
   "source": [
    "### Translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de41b5c-9421-4b6c-a467-53a34887f540",
   "metadata": {},
   "source": [
    "Here we define a **translate_sequence** function. It tokenizes the input sentence, adds < sos > and < eos > tokens at the beginning and end respectively, converts the tokens to indices using the vocabulary of the pli field, converts the indices to a PyTorch tensor, and iteratively predicts the next token in the translated sequence using the trained model until either the < eos > token is predicted or the maximum length is reached. Finally, it converts the predicted indices back to tokens using the vocabulary of the Kotlin field and returns the translated sentence, removing the start token < sos > as it is only used for signaling the model to start generation and is not part of the actual translated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a95ad7-9cd8-4e50-957b-a7640de1ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sequence(sentence, pli, ktl, device, max_length=50):\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.lower() for token in sentence.split()]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "\n",
    "    tokens.insert(0, pli.init_token)\n",
    "    tokens.append(pli.eos_token)\n",
    "\n",
    "    # Iterate  each languae token and convert to an index\n",
    "    text_to_indices = [pli.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [ktl.vocab.stoi[\"<sos>\"]]\n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == ktl.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [ktl.vocab.itos[idx] for idx in outputs]\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad703ec-769e-4d94-8094-6a3c0ef12579",
   "metadata": {},
   "source": [
    "### Transpile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596f25f-d79e-4979-8948-deabfa76b81e",
   "metadata": {},
   "source": [
    "We also define a **transpile_sequence** function. It retrieves the code tokens and context data from the input dictionary. Then, it initializes an empty list to store the transpiled code with proper indentation. The function then iterates through the tokens, adjusting the indentation level based on curly braces {} encountered in the code. It ignores the <eos> token. And after iterating through all the tokens, the function joins the transpiled code with proper spacing and renders it using the contextual data. Finally, it returns the transpiled code and the updated indentation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b965e5-5119-496c-94c1-9f19923c2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpile_sequence(translated, level):\n",
    "    tokens = translated[\"code\"]\n",
    "    data = translated[\"context\"]\n",
    "    lint = []\n",
    "\n",
    "    for t in tokens:\n",
    "        spacer = \"\".rjust(level * 4)\n",
    "        if t == \"{\":\n",
    "            level += 1\n",
    "        elif t == \"}\" and level > 0:\n",
    "            level -= 1\n",
    "            spacer = \"\".rjust(level * 4)\n",
    "\n",
    "        if t != \"<eos>\":\n",
    "            lint.append(spacer + t)\n",
    "\n",
    "    code = \" \".join(lint)\n",
    "    t = Template(code)\n",
    "\n",
    "    return t.render(data), level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafe7d05-e059-4d68-960a-fb7e28acd116",
   "metadata": {},
   "source": [
    "## Specifics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2848f0-328f-4a97-960d-841062bde337",
   "metadata": {},
   "source": [
    "Before defining the final parameters and training our model we have a few useful functions to define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c3478-ec6a-4ea6-a017-f9e85b954645",
   "metadata": {},
   "source": [
    "This **remove_eos** function removes all < eos > tokens and then concatenate the remaining tokens into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be32739-c740-4b1b-aeba-7456382557f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_eos(witheos):\n",
    "    noeos = []\n",
    "    for w in witheos:\n",
    "        if w != '<eos>':\n",
    "            noeos.append(w)\n",
    "    return \" \".join(noeos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4cd401-94c7-4c5b-8b01-9c7bae96d102",
   "metadata": {},
   "source": [
    "The following functions, **save_checkpoint** and **load_checkpoint**, are essential for saving and loading the state of our model during training or inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c400ac17-190a-4c16-9739-cdd54edc2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7c546-2c41-4705-8ad5-52a6795a5673",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19623d04-e9bf-45ce-8106-b4590eb70a13",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4823c-a5fd-451c-911b-434081ae5190",
   "metadata": {},
   "source": [
    "We start by defining some **model hyperparameters** that help define how our model processes and transforms our input data. We also define some **training hyperparameters** that regulate the training process of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08426766-1700-48c7-b48a-8f9d12fab20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready to define everything we need for training our Seq2Seq model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "load_model = True\n",
    "save_model = True\n",
    "\n",
    "# Model hyperparameters\n",
    "src_vocab_size = len(pli.vocab)\n",
    "trg_vocab_size = len(ktl.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dropout = 0.10\n",
    "max_len = 100\n",
    "forward_expansion = 4\n",
    "src_pad_idx = ktl.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "global level\n",
    "# Training hyperparameters\n",
    "num_epochs = 300\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "training_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6674fb-ac75-40c0-a3ba-8214e868a38e",
   "metadata": {},
   "source": [
    "### Model Initialization and Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b6171-3c47-4603-9b68-a0ad39d8d14b",
   "metadata": {},
   "source": [
    "We then **initialize** the **model**, **optimizer**, **scheduler**, and **criterion** for training a Transformer model. we also create **iterators** for the training and test datasets that facillitate efficient data management, improve computational efficiency, and enhance the overall training process's effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "685f48ba-4676-4cc7-9506-69b8de07f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, test),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.p),\n",
    "    device=device,\n",
    ")\n",
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "pad_idx = ktl.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655be9a-b42d-49b4-a31d-cb3423b11219",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1d111-ccfc-479f-ab39-efa30c3d2f53",
   "metadata": {},
   "source": [
    "Finaly we define our custom training loop. Within the training loop, batches of data are fetched using the **training_iterator**. Input and target sequences are transferred to the appropriate device (CPU or GPU), and the model is then trained using **forward** and **backward** passes. **Gradient clipping** is applied to prevent exploding gradients, and the **optimizer** is used to update the model parameters based on the computed gradients. After training, we evaluate the model's performance on example pli sequences, translating them to Kotlin using the trained model. Finally we utilise matplotlib to visualize the training loss over iterations and optionally save the trained model checkpoint for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45a6cb24-b320-452a-ade5-509323d2b49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 300]\n",
      "Translated example sentence:\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> () () <pad> <pad> <pad> <pad>\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Last 5 training losses: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50 / 300]\n",
      "Translated example sentence:\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.11536741256713867, 0.13401655852794647, 0.09288042783737183, 0.0880018100142479, 0.0810730904340744]\n",
      "[Epoch 100 / 300]\n",
      "Translated example sentence:\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.002143696416169405, 0.0021836746018379927, 0.002142140408977866, 0.0020195324905216694, 0.0023125687148422003]\n",
      "Epoch   125: reducing learning rate of group 0 to 3.0000e-05.\n",
      "Epoch   145: reducing learning rate of group 0 to 3.0000e-06.\n",
      "[Epoch 150 / 300]\n",
      "Translated example sentence:\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.0009272661409340799, 0.0009802684653550386, 0.0009581581107340753, 0.0009119620081037283, 0.0009031783556565642]\n",
      "Epoch   156: reducing learning rate of group 0 to 3.0000e-07.\n",
      "Epoch   167: reducing learning rate of group 0 to 3.0000e-08.\n",
      "Epoch   178: reducing learning rate of group 0 to 3.0000e-09.\n",
      "[Epoch 200 / 300]\n",
      "Translated example sentence:\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.0009122670162469149, 0.0009905740153044462, 0.0010367712238803506, 0.0011590280337259173, 0.0010337315034121275]\n",
      "[Epoch 250 / 300]\n",
      "Translated example sentence:\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.001014587003737688, 0.0008746228413656354, 0.001056693377904594, 0.0011161871952936053, 0.001087463111616671]\n",
      "[Epoch 300 / 300]\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.0009633959271013737, 0.0010461953934282064, 0.0010198841337114573, 0.0018401391571387649, 0.0009006673935800791]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for epoch in range(num_epochs):\n",
    "        model.eval()\n",
    "        # little bit of output to check the progress\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "            # Iterate over the dataset and extract PLI sequences\n",
    "            sentences = [\n",
    "                    {'pli': ['PROCEDURE', 'MAIN', '{{type0}}', '{{type1}}'],\n",
    "                     'context': {'type0': 'Array', 'type1': 'String'}},\n",
    "                    {'pli': ['DO'], 'context': {}},\n",
    "                    {'pli': ['END'], 'context': {}}\n",
    "                ]\n",
    "            print(f\"Translated example sentence:\")\n",
    "            level = 0\n",
    "            for s in sentences:\n",
    "                translated = translate_sequence(\n",
    "                    s['pli'], pli, ktl, device, max_length=50\n",
    "                )\n",
    "                transpiled, level = transpile_sequence({\n",
    "                    'code': translated,\n",
    "                    'context': s['context']\n",
    "                }, level)\n",
    "                print(f\"{transpiled}\")\n",
    "            last_5_losses = training_losses[-5:]\n",
    "            print(\"Last 5 training losses:\", last_5_losses)\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for batch_idx, batch in enumerate(train_iterator):\n",
    "            # Get input and targets and get to cuda\n",
    "            inp_data = batch.p.to(device)\n",
    "            target = batch.k.to(device)\n",
    "            # Forward\n",
    "            output = model(inp_data, target[:-1, :])\n",
    "            output = output.reshape(-1, output.shape[2])\n",
    "            target = target[1:].reshape(-1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target)\n",
    "            losses.append(loss.item())\n",
    "            # Back prop\n",
    "            loss.backward()\n",
    "            # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "            # within a healthy range\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            # Gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "            training_losses.append(loss.item())\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        scheduler.step(mean_loss)\n",
    "     # Print the final epoch\n",
    "    print(f\"[Epoch {num_epochs} / {num_epochs}]\")\n",
    "    # Iterate over the dataset and extract PLI sequences\n",
    "    for s in sentences:\n",
    "        translated = translate_sequence(\n",
    "            s['pli'], pli, ktl, device, max_length=50\n",
    "        )\n",
    "        transpiled, level = transpile_sequence({\n",
    "            'code': translated,\n",
    "            'context': s['context']\n",
    "        }, level)\n",
    "        print(f\"{transpiled}\")\n",
    "        # Translate and transpile here if needed\n",
    "    last_5_losses = training_losses[-5:]\n",
    "    print(\"Last 5 training losses:\", last_5_losses)\n",
    "\n",
    "    plt.plot(training_losses, label='Training Loss')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('training_losses')\n",
    "    plt.title('Training Loss Over Iterations')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "if save_model:\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    save_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138879f-8b33-41bc-898a-9e3611f82c08",
   "metadata": {},
   "source": [
    "## Running the Transpiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45909bb6-a9fc-4f7b-9288-59cb5e9d1997",
   "metadata": {},
   "source": [
    "And as little bonus we can show you an example of how our transpiller works. We define a **run_model** function where we're processing a PL1 file, which contains original PL1 code. We then load our pre-trained model and its optimizer using the checkpoint file. We set up a lexer and parser for the PL1 code using ANTLR4. We generate a dataset from the parsed code using a visitor pattern, which iterates through the AST (Abstract Syntax Tree) generated by the parser. For each statement in the PL1 code, we translate it into Kotlin using our sequence-to-sequence model and transpile it into Kotlin code. The transpiled Kotlin code is accumulated and printed as the output. This function essentially automates the process of translating our PL1 code to Kotlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7520bf5d-6902-41ee-bb85-956ca92b52b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PL1:\n",
      "\n",
      " Factorial: proc options (main);\n",
      "    dcl (n,result) fixed bin(31);\n",
      "    n  = 5;\n",
      "    result = Compute_factorial(n);\n",
      "\n",
      " end Factorial;\n",
      "  /***********************************************/\n",
      "  /* Subroutine                                  */\n",
      "  /***********************************************/\n",
      "  Compute_factorial: proc (n)  returns (fixed bin(31));\n",
      "     dcl n fixed bin(15);\n",
      "      if n <= 1 then\n",
      "        return(1);\n",
      "\n",
      "     return( n*Compute_factorial(n-1) );\n",
      "\n",
      "  end Compute_factorial;\n",
      "\n",
      "\n",
      "=> Loading checkpoint\n",
      "KTL:\n",
      "\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "    var     n : Int\n",
      "    var     result : Int\n",
      "    n = 5\n",
      "    result = compute_factorial(n)\n",
      "}\n",
      "fun compute_factorial(n : Int) : Int\n",
      "{\n",
      "    if(n<=1)\n",
      "    {\n",
      "        return 1\n",
      "    }\n",
      "    return n*compute_factorial(n-1)\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_model(filename):\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        original_code = file.read()\n",
    "    print(\"PL1:\")\n",
    "    print(original_code)\n",
    "    print()\n",
    "\n",
    "    load_checkpoint(torch.load(\"checkpoint.pth.tar\"), model, optimizer)\n",
    "    # Lexer setup\n",
    "    input_stream = FileStream(filename)\n",
    "    lexer = PLILexer(input_stream)\n",
    "    stream = CommonTokenStream(lexer)\n",
    "\n",
    "    # Parser setup\n",
    "    parser = PLIParser(stream)\n",
    "    tree = parser.program()\n",
    "\n",
    "    # Dataset generation\n",
    "    visitor = PLIVisitor()\n",
    "    statements = visitor.visit(tree)\n",
    "\n",
    "    # Accumulate transpiled sequences\n",
    "    transpiled_code = \"\"\n",
    "    level = 0\n",
    "    for s in statements:\n",
    "        translated = translate_sequence(\n",
    "            s[\"pli\"], pli, ktl, device, max_length=50\n",
    "        )\n",
    "        transpiled, level = transpile_sequence({\n",
    "            'code': translated,\n",
    "            'context': s['context']\n",
    "        }, level)\n",
    "        transpiled_code += transpiled+ \"\\n\"\n",
    "\n",
    "    # Print the entire block of transpiled code\n",
    "    print(\"KTL:\")\n",
    "    print(\"\\n\" + transpiled_code)\n",
    "\n",
    "# Example usage:\n",
    "filename = \"FIB.PLI\"  # Replace with the actual filename\n",
    "run_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ef4ca-68ef-4240-9749-b644d19e15fc",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632de120-96d8-4e93-b0c8-d38b27f86a91",
   "metadata": {},
   "source": [
    "And there you have it ! This notebook provides a comprehensive look at building and training a Seq2Seq Transformer model in PyTorch, from scratch, for in this case the specific task of transpiling PL/I code to Kotlin. The model not only demonstrates the capabilities of neural networks in handling language translation tasks but also highlights the flexibility of the Transformer architecture in processing sequence data.\n",
    "\n",
    "For those interested in further exploring machine translation models, another article is available where I utilize the Hugging Face API to achieve similar tasks. This API simplifies many of the steps covered here and provides powerful tools to be able to deploy machine translation models in production environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
