{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1da560-8eed-4a96-a97c-7aecc57bff6e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f43e528-92db-41c9-b8b0-8f8f9092214b",
   "metadata": {},
   "source": [
    "This notebook presents an implementation of a **sequence-to-sequence** (Seq2Seq) model using PyTorch. The model, built from scratch, leverages the **Transformer** architecture, a state-of-the-art model for sequence transduction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6692af6-f6dc-486a-b369-7918d54a74cf",
   "metadata": {},
   "source": [
    "## Installing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b3233-744a-4e32-8b62-6d1010689fd9",
   "metadata": {},
   "source": [
    "We begin with the installation of essential libraries. We'll be relying on the robust capabilities of **PyTorch**, **TorchText**, and **ANTLR4** to bring our transpiler to life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c39b85a-ad6e-461a-9220-4c96dcca837a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:41.843609Z",
     "iopub.status.busy": "2024-04-23T12:28:41.842975Z",
     "iopub.status.idle": "2024-04-23T12:28:58.407619Z",
     "shell.execute_reply": "2024-04-23T12:28:58.405457Z",
     "shell.execute_reply.started": "2024-04-23T12:28:41.843560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.9/dist-packages (1.7.1)\n",
      "Requirement already satisfied: torchvision==0.8.2 in /usr/local/lib/python3.9/dist-packages (0.8.2)\n",
      "Requirement already satisfied: torchaudio==0.7.2 in /usr/local/lib/python3.9/dist-packages (0.7.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1) (1.23.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.8.2) (9.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchtext==0.8.1 in /usr/local/lib/python3.9/dist-packages (0.8.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (4.64.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (1.23.4)\n",
      "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (1.7.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1->torchtext==0.8.1) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchtext==0.8.1) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.8.1) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.8.1) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchtext==0.8.1) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: antlr4-python3-runtime==4.9.2 in /usr/local/lib/python3.9/dist-packages (4.9.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2\n",
    "!pip install torchtext==0.8.1\n",
    "!pip install antlr4-python3-runtime==4.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ab93a-68f0-429a-85e8-8f68a11eb997",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa76569-0e4e-4ede-b67f-ee5a3b2408b5",
   "metadata": {},
   "source": [
    "We then import all the necessary libraries. **json** will be used to import our data, **antlr4** provides the backbone for our transpiler, enabling us to parse PL/I code and manipulate its structure with ease, **torch** PyTorch empowers us to build and train neural networks seamlessly, **torchtext** complements PyTorch by providing utilities for text processing and dataset handling, **jinja2** simplifies code generation with its template engine ensuring a smooth transition between languages and to finish **matplotlib** will come in handy during training for visualising our progress  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa9b17b-24bf-4cb8-860c-fb1ed8bb988a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.411815Z",
     "iopub.status.busy": "2024-04-23T12:28:58.411237Z",
     "iopub.status.idle": "2024-04-23T12:28:58.422801Z",
     "shell.execute_reply": "2024-04-23T12:28:58.420411Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.411769Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from antlr4 import *\n",
    "from pli.PLILexer import PLILexer\n",
    "from pli.PLIParser import PLIParser\n",
    "from pli.PLIVisitor import PLIVisitor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "\n",
    "from jinja2 import Template\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c450d3e-f442-45f2-bfe1-d3512e6b61ec",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1871b9-794a-4243-813f-dc90d1576328",
   "metadata": {},
   "source": [
    "The Transformer class encapsulates a custom implementation of the Transformer model, a powerful architecture for **sequence-to-sequence** tasks. It comprises various components, including **embedding layers** for source and target sequences, **positional embeddings** to capture sequence order, and a multi-layer Transformer module. The model utilizes **dropout** for regularization and employs **masks** to handle padding and prevent information leakage during training. With these components, the Transformer class can efficiently process source and target sequences, facilitating tasks like language translation or code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83a751df-600d-4f8a-addf-a8e9ddda6cbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:44:14.017111Z",
     "iopub.status.busy": "2024-04-23T12:44:14.015950Z",
     "iopub.status.idle": "2024-04-23T12:44:14.034473Z",
     "shell.execute_reply": "2024-04-23T12:44:14.032371Z",
     "shell.execute_reply.started": "2024-04-23T12:44:14.017040Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    # Initialises the Transformer model\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_size,\n",
    "            src_vocab_size,\n",
    "            trg_vocab_size,\n",
    "            src_pad_idx,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_len,\n",
    "            device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    # Generates a mask for the source sequence to handle padding\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "\n",
    "        # (N, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    # Forward pass of the Transformer model\n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "                .unsqueeze(1)\n",
    "                .expand(src_seq_length, N)\n",
    "                .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "                .unsqueeze(1)\n",
    "                .expand(trg_seq_length, N)\n",
    "                .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        )\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f95555c-514a-4ba7-a729-e7c5c88edb11",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ea9c3-0261-427e-99a3-2b293a694685",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b8c6d-5dfb-4b20-a80b-95309cf8a8dc",
   "metadata": {},
   "source": [
    "We define a simple **tokenizer** that splits a string into tokens based on whitespace, it then creates two **Field** objects with some specifications and finally we create a dictionary that maps field names to tuples to be used later to specify how to load and process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c127116-54cb-4570-84cc-73ebb591f2a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.453342Z",
     "iopub.status.busy": "2024-04-23T12:28:58.452701Z",
     "iopub.status.idle": "2024-04-23T12:28:58.464816Z",
     "shell.execute_reply": "2024-04-23T12:28:58.462810Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.453299Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchtext.data as data\n",
    "\n",
    "tokenizer = lambda x: x.split()\n",
    "\n",
    "pli = data.Field(sequential=True, use_vocab=True, tokenize=tokenizer, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "ktl = data.Field(sequential=True, use_vocab=True, tokenize=tokenizer, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "fields = {'pli': ('p', pli), 'ktl': ('k', ktl)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1161956e-fb38-484e-a7ea-1ce7e074183d",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb0945-e0d9-4a1d-be24-969287dc3c59",
   "metadata": {},
   "source": [
    "We're using the TabularDataset module from the torchtext.data package to create separate datasets for **training** and **testing**. The data is loaded from JSON files located in the 'data' directory. We specify the format of the data as JSON and define the fields to be extracted from the JSON files using the fields parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf949e1f-8a60-401d-9f6e-8f81c9e4d0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.468127Z",
     "iopub.status.busy": "2024-04-23T12:28:58.467575Z",
     "iopub.status.idle": "2024-04-23T12:28:58.484013Z",
     "shell.execute_reply": "2024-04-23T12:28:58.481931Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.468086Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = data.TabularDataset.splits(\n",
    "    path='data',\n",
    "    train='train.json',\n",
    "    test='test.json',\n",
    "    format='json',\n",
    "    fields=fields,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c78c8-e6e8-4176-94a6-c64c7e578db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T09:30:39.739005Z",
     "iopub.status.busy": "2024-04-17T09:30:39.738420Z",
     "iopub.status.idle": "2024-04-17T09:30:39.745689Z",
     "shell.execute_reply": "2024-04-17T09:30:39.744054Z",
     "shell.execute_reply.started": "2024-04-17T09:30:39.738961Z"
    }
   },
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b84fb3-181b-486f-9de3-7f1bb362f716",
   "metadata": {},
   "source": [
    "Building a vocabulary involves creating a dictionary that maps each unique word in the dataset to a unique index. This process is crucial for natural language processing tasks as it allows machine learning models to represent words as numerical values, which they can process and understand. In this case, we're building vocabularies for the PL/I (pli) and Kotlin (ktl) datasets, ensuring that the model has a predefined set of words it can understand and process during training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e493b0-806b-4216-a4e6-2c94932c8bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.486607Z",
     "iopub.status.busy": "2024-04-23T12:28:58.486164Z",
     "iopub.status.idle": "2024-04-23T12:28:58.495435Z",
     "shell.execute_reply": "2024-04-23T12:28:58.493234Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.486566Z"
    }
   },
   "outputs": [],
   "source": [
    "pli.build_vocab(train, max_size=10000, min_freq=1)\n",
    "ktl.build_vocab(train, max_size=10000, min_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63006ee-e498-43b8-ad3a-0a087e687ac5",
   "metadata": {},
   "source": [
    "### Translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de41b5c-9421-4b6c-a467-53a34887f540",
   "metadata": {},
   "source": [
    "We define a **translate_sequence** function. It tokenizes the input sentence, adds <SOS> and <EOS> tokens at the beginning and end respectively, converts the tokens to indices using the vocabulary of the pli field, converts the indices to a PyTorch tensor, and iteratively predicts the next token in the translated sequence using the trained model until either the <EOS> token is predicted or the maximum length is reached. Finally, it converts the predicted indices back to tokens using the vocabulary of the Kotlin field and returns the translated sentence, removing the start token <sos>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16a95ad7-9cd8-4e50-957b-a7640de1ab3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.499006Z",
     "iopub.status.busy": "2024-04-23T12:28:58.498374Z",
     "iopub.status.idle": "2024-04-23T12:28:58.515843Z",
     "shell.execute_reply": "2024-04-23T12:28:58.513145Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.498961Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_sequence(sentence, pli, ktl, device, max_length=50):\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.lower() for token in sentence.split()]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "\n",
    "    tokens.insert(0, pli.init_token)\n",
    "    tokens.append(pli.eos_token)\n",
    "\n",
    "    # Iterate  each languae token and convert to an index\n",
    "    text_to_indices = [pli.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [ktl.vocab.stoi[\"<sos>\"]]\n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == ktl.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [ktl.vocab.itos[idx] for idx in outputs]\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad703ec-769e-4d94-8094-6a3c0ef12579",
   "metadata": {},
   "source": [
    "### Transpile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596f25f-d79e-4979-8948-deabfa76b81e",
   "metadata": {},
   "source": [
    "We define a **transpile_sequence** function. It retrieves the code tokens and context data from the input dictionary. Then, it initializes an empty list to store the transpiled code with proper indentation. The function then iterates through the tokens, adjusting the indentation level based on curly braces {} encountered in the code. It ignores the <eos> token. And after iterating through all the tokens, the function joins the transpiled code with proper spacing and renders it using the contextual data. Finally, it returns the transpiled code and the updated indentation level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7b965e5-5119-496c-94c1-9f19923c2d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.519443Z",
     "iopub.status.busy": "2024-04-23T12:28:58.518285Z",
     "iopub.status.idle": "2024-04-23T12:28:58.530245Z",
     "shell.execute_reply": "2024-04-23T12:28:58.528476Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.519376Z"
    }
   },
   "outputs": [],
   "source": [
    "def transpile_sequence(translated, level):\n",
    "    tokens = translated[\"code\"]\n",
    "    data = translated[\"context\"]\n",
    "    lint = []\n",
    "\n",
    "    for t in tokens:\n",
    "        spacer = \"\".rjust(level * 4)\n",
    "        if t == \"{\":\n",
    "            level += 1\n",
    "        elif t == \"}\" and level > 0:\n",
    "            level -= 1\n",
    "            spacer = \"\".rjust(level * 4)\n",
    "\n",
    "        if t != \"<eos>\":\n",
    "            lint.append(spacer + t)\n",
    "\n",
    "    code = \" \".join(lint)\n",
    "    t = Template(code)\n",
    "\n",
    "    return t.render(data), level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7c546-2c41-4705-8ad5-52a6795a5673",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19623d04-e9bf-45ce-8106-b4590eb70a13",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4823c-a5fd-451c-911b-434081ae5190",
   "metadata": {},
   "source": [
    "We define some **model hyperparameters** that help define how our model processes and transforms our input data. We also define some **training hyperparameters** that regulate the training process of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08426766-1700-48c7-b48a-8f9d12fab20c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.533476Z",
     "iopub.status.busy": "2024-04-23T12:28:58.532912Z",
     "iopub.status.idle": "2024-04-23T12:28:58.546249Z",
     "shell.execute_reply": "2024-04-23T12:28:58.544288Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.533431Z"
    }
   },
   "outputs": [],
   "source": [
    "# ready to define everything we need for training our Seq2Seq model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "load_model = True\n",
    "save_model = True\n",
    "\n",
    "# Model hyperparameters\n",
    "src_vocab_size = len(pli.vocab)\n",
    "trg_vocab_size = len(ktl.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dropout = 0.10\n",
    "max_len = 100\n",
    "forward_expansion = 4\n",
    "src_pad_idx = ktl.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "global level\n",
    "# Training hyperparameters\n",
    "num_epochs = 150\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "training_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd83f2c-6d63-44b0-88bc-269aaa7e32f4",
   "metadata": {},
   "source": [
    "### Specifics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5a25e-8d9e-41d8-b800-8c623f3e2c63",
   "metadata": {},
   "source": [
    "This **remove_eos** function removes all \"< eos >\" tokens and then concatenate the remaining tokens into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "470fdc5a-d58f-417d-a82a-b7a65842b098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.552515Z",
     "iopub.status.busy": "2024-04-23T12:28:58.551974Z",
     "iopub.status.idle": "2024-04-23T12:28:58.561886Z",
     "shell.execute_reply": "2024-04-23T12:28:58.559473Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.552478Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_eos(witheos):\n",
    "    noeos = []\n",
    "    for w in witheos:\n",
    "        if w != '<eos>':\n",
    "            noeos.append(w)\n",
    "    return \" \".join(noeos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f282dd-3afc-4d7c-b9db-6f558e81e77c",
   "metadata": {},
   "source": [
    "\n",
    "These functions, **save_checkpoint** and **load_checkpoint**, are essential for saving and loading the state of a model during training or inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc4e57c0-6e30-4d3a-adae-4c35d4a7045f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.565223Z",
     "iopub.status.busy": "2024-04-23T12:28:58.564750Z",
     "iopub.status.idle": "2024-04-23T12:28:58.577090Z",
     "shell.execute_reply": "2024-04-23T12:28:58.574468Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.565186Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6674fb-ac75-40c0-a3ba-8214e868a38e",
   "metadata": {},
   "source": [
    "### Model Initialization and Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b6171-3c47-4603-9b68-a0ad39d8d14b",
   "metadata": {},
   "source": [
    "Here we **initialize** the model, optimizer, scheduler, and criterion for training a Transformer model. It also creates **iterators** for the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "685f48ba-4676-4cc7-9506-69b8de07f19d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:28:58.579484Z",
     "iopub.status.busy": "2024-04-23T12:28:58.578994Z",
     "iopub.status.idle": "2024-04-23T12:28:59.207455Z",
     "shell.execute_reply": "2024-04-23T12:28:59.205975Z",
     "shell.execute_reply.started": "2024-04-23T12:28:58.579437Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, test),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.p),\n",
    "    device=device,\n",
    ")\n",
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "pad_idx = ktl.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655be9a-b42d-49b4-a31d-cb3423b11219",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e1d111-ccfc-479f-ab39-efa30c3d2f53",
   "metadata": {},
   "source": [
    "Within the training loop, batches of data are fetched using the **training_iterator**. Input and target sequences are transferred to the appropriate device (CPU or GPU), and the model is then trained using **forward** and **backward** passes. **Gradient clipping** is applied to prevent exploding gradients, and the **optimizer** is used to update the model parameters based on the computed gradients. After training, we evaluate the model's performance on example pli sequences, translating them to Kotlin using the trained model. Finally we utilise matplotlib to visualize the training loss over iterations and optionally save the trained model checkpoint for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45a6cb24-b320-452a-ade5-509323d2b49c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:57:23.432122Z",
     "iopub.status.busy": "2024-04-23T12:57:23.431278Z",
     "iopub.status.idle": "2024-04-23T12:57:47.872870Z",
     "shell.execute_reply": "2024-04-23T12:57:47.870428Z",
     "shell.execute_reply.started": "2024-04-23T12:57:23.432055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 150]\n",
      "Translated example sentence:\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.0010398576268926263, 0.0009446950280107558, 0.0011541706044226885, 0.0009388906182721257, 0.0008597169071435928]\n",
      "[Epoch 50 / 150]\n",
      "Translated example sentence:\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.0009497507708147168, 0.0007547992863692343, 0.0007884445367380977, 0.0007842038758099079, 0.0008303519571200013]\n",
      "[Epoch 100 / 150]\n",
      "Translated example sentence:\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.0008076311205513775, 0.0008211977547034621, 0.0009123978670686483, 0.0010878389002755284, 0.0008459058008156717]\n",
      "[Epoch 150 / 150]\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "}\n",
      "Last 5 training losses: [0.000833471363876015, 0.0008147450862452388, 0.0011860905215144157, 0.0009011754300445318, 0.0007047638646326959]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for epoch in range(num_epochs):\n",
    "        model.eval()\n",
    "        # little bit of output to check the progress\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "            # Iterate over the dataset and extract PLI sequences\n",
    "            sentences = [\n",
    "                    {'pli': ['PROCEDURE', 'MAIN', '{{type0}}', '{{type1}}'],\n",
    "                     'context': {'type0': 'Array', 'type1': 'String'}},\n",
    "                    {'pli': ['DO'], 'context': {}},\n",
    "                    {'pli': ['END'], 'context': {}}\n",
    "                ]\n",
    "            print(f\"Translated example sentence:\")\n",
    "            level = 0\n",
    "            for s in sentences:\n",
    "                translated = translate_sequence(\n",
    "                    s['pli'], pli, ktl, device, max_length=50\n",
    "                )\n",
    "                transpiled, level = transpile_sequence({\n",
    "                    'code': translated,\n",
    "                    'context': s['context']\n",
    "                }, level)\n",
    "                print(f\"{transpiled}\")\n",
    "            last_5_losses = training_losses[-5:]\n",
    "            print(\"Last 5 training losses:\", last_5_losses)\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for batch_idx, batch in enumerate(train_iterator):\n",
    "            # Get input and targets and get to cuda\n",
    "            inp_data = batch.p.to(device)\n",
    "            target = batch.k.to(device)\n",
    "            # Forward\n",
    "            output = model(inp_data, target[:-1, :])\n",
    "            output = output.reshape(-1, output.shape[2])\n",
    "            target = target[1:].reshape(-1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target)\n",
    "            losses.append(loss.item())\n",
    "            # Back prop\n",
    "            loss.backward()\n",
    "            # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "            # within a healthy range\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            # Gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "            training_losses.append(loss.item())\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        scheduler.step(mean_loss)\n",
    "     # Print the final epoch\n",
    "    print(f\"[Epoch {num_epochs} / {num_epochs}]\")\n",
    "    # Iterate over the dataset and extract PLI sequences\n",
    "    for s in sentences:\n",
    "        translated = translate_sequence(\n",
    "            s['pli'], pli, ktl, device, max_length=50\n",
    "        )\n",
    "        transpiled, level = transpile_sequence({\n",
    "            'code': translated,\n",
    "            'context': s['context']\n",
    "        }, level)\n",
    "        print(f\"{transpiled}\")\n",
    "        # Translate and transpile here if needed\n",
    "    last_5_losses = training_losses[-5:]\n",
    "    print(\"Last 5 training losses:\", last_5_losses)\n",
    "\n",
    "    plt.plot(training_losses, label='Training Loss')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('training_losses')\n",
    "    plt.title('Training Loss Over Iterations')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "if save_model:\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    save_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138879f-8b33-41bc-898a-9e3611f82c08",
   "metadata": {},
   "source": [
    "### Running the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45909bb6-a9fc-4f7b-9288-59cb5e9d1997",
   "metadata": {},
   "source": [
    "Finally, to show how our transpiller works, we define a **run_model** function where we're processing a PL1 file, which contains original PL1 code. First, we load our pre-trained model and its optimizer using the checkpoint file. Then, we set up a lexer and parser for the PL1 code using ANTLR4. We generate a dataset from the parsed code using a visitor pattern, which iterates through the AST (Abstract Syntax Tree) generated by the parser. For each statement in the PL1 code, we translate it into Kotlin using our sequence-to-sequence model and transpile it into Kotlin code. The transpiled Kotlin code is accumulated and printed as the output. This function essentially automates the process of translating our PL1 code to Kotlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7520bf5d-6902-41ee-bb85-956ca92b52b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T12:29:26.571588Z",
     "iopub.status.busy": "2024-04-23T12:29:26.568262Z",
     "iopub.status.idle": "2024-04-23T12:29:29.184686Z",
     "shell.execute_reply": "2024-04-23T12:29:29.183334Z",
     "shell.execute_reply.started": "2024-04-23T12:29:26.571500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PL1:\n",
      "\n",
      " Factorial: proc options (main);\n",
      "    dcl (n,result) fixed bin(31);\n",
      "    n  = 5;\n",
      "    result = Compute_factorial(n);\n",
      "\n",
      " end Factorial;\n",
      "  /***********************************************/\n",
      "  /* Subroutine                                  */\n",
      "  /***********************************************/\n",
      "  Compute_factorial: proc (n)  returns (fixed bin(31));\n",
      "     dcl n fixed bin(15);\n",
      "      if n <= 1 then\n",
      "        return(1);\n",
      "\n",
      "     return( n*Compute_factorial(n-1) );\n",
      "\n",
      "  end Compute_factorial;\n",
      "\n",
      "\n",
      "=> Loading checkpoint\n",
      "KTL:\n",
      "\n",
      "fun main (args: Array<String>)\n",
      "{\n",
      "    var     n : Int\n",
      "    var     result : Int\n",
      "    n = 5\n",
      "    result = compute_factorial(n)\n",
      "}\n",
      "fun compute_factorial(n : Int) : Int\n",
      "{\n",
      "    if(n<=1)\n",
      "    {\n",
      "        return 1\n",
      "    }\n",
      "    return n*compute_factorial(n-1)\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_model(filename):\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        original_code = file.read()\n",
    "    print(\"PL1:\")\n",
    "    print(original_code)\n",
    "    print()\n",
    "\n",
    "    load_checkpoint(torch.load(\"checkpoint.pth.tar\"), model, optimizer)\n",
    "    # Lexer setup\n",
    "    input_stream = FileStream(filename)\n",
    "    lexer = PLILexer(input_stream)\n",
    "    stream = CommonTokenStream(lexer)\n",
    "\n",
    "    # Parser setup\n",
    "    parser = PLIParser(stream)\n",
    "    tree = parser.program()\n",
    "\n",
    "    # Dataset generation\n",
    "    visitor = PLIVisitor()\n",
    "    statements = visitor.visit(tree)\n",
    "\n",
    "    # Accumulate transpiled sequences\n",
    "    transpiled_code = \"\"\n",
    "    level = 0\n",
    "    for s in statements:\n",
    "        translated = translate_sequence(\n",
    "            s[\"pli\"], pli, ktl, device, max_length=50\n",
    "        )\n",
    "        transpiled, level = transpile_sequence({\n",
    "            'code': translated,\n",
    "            'context': s['context']\n",
    "        }, level)\n",
    "        transpiled_code += transpiled+ \"\\n\"\n",
    "\n",
    "    # Print the entire block of transpiled code\n",
    "    print(\"KTL:\")\n",
    "    print(\"\\n\" + transpiled_code)\n",
    "\n",
    "# Example usage:\n",
    "filename = \"FIB.PLI\"  # Replace with the actual filename\n",
    "run_model(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
