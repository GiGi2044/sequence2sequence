{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb7a759-0017-4bdb-8459-3838fbfd0af0",
   "metadata": {},
   "source": [
    "## Setup & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c06e59d-fedb-42be-aea3-e4fd1863c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[1G\u001b[1myarn add v1.22.21\u001b[22m\n",
      "\u001b[2K\u001b[1G\u001b[34minfo\u001b[39m No lockfile found.\n",
      "\u001b[2K\u001b[1G\u001b[2m[1/4]\u001b[22m ðŸ”  Resolving packages...\n",
      "\u001b[1Gâ  \u001b[0K\u001b[1Gâ ‚ @langchain/community\u001b[0K\u001b[1Gâ „ @langchain/community\u001b[0K\u001b[1Gâ¡€ zod-to-json-schema@^3.22.5\u001b[0K\u001b[1Gâ¢€ zod-to-json-schema@^3.22.5\u001b[0K\u001b[1Gâ   uuid@^9.0.0\u001b[0K\u001b[1Gâ  zod-to-json-schema@^3.22.3\u001b[0K\u001b[1Gâ ˆ ml-tree-similarity@^1.0.0\u001b[0K\u001b[1Gâ  ml-array-sum@^1.1.6\u001b[0K\u001b[1Gâ ‚ form-data@^4.0.0\u001b[0K\u001b[1Gâ „ is-any-array@^2.0.0\u001b[0K\u001b[1Gâ¡€ whatwg-url@^5.0.0\u001b[0K\u001b[1Gâ¢€ mime-types@^2.1.12\u001b[0K\u001b[1Gâ   delayed-stream@~1.0.0\u001b[0K\u001b[1Gâ  mime-db@1.52.0\u001b[0K\u001b[1Gâ ˆ base64-js@^1.5.1\u001b[0K\u001b[1Gâ  base64-js@^1.5.1\u001b[0K\u001b[2K\u001b[1G\u001b[2K\u001b[1G\u001b[2m[2/4]\u001b[22m ðŸšš  Fetching packages...\n",
      "\u001b[2K\u001b[1G\u001b[1G[---------------------------------------------------------] 0/57\u001b[2K\u001b[1G\u001b[31merror\u001b[39m @langchain/core@0.1.62: The engine \"node\" is incompatible with this module. Expected version \">=18\". Got \"16.15.1\"\n",
      "\u001b[2K\u001b[1G\u001b[31merror\u001b[39m Found incompatible module.\n",
      "\u001b[2K\u001b[1G\u001b[34minfo\u001b[39m Visit \u001b[1mhttps://yarnpkg.com/en/docs/cli/add\u001b[22m for documentation about this command.\n",
      "\u001b[2K\u001b[1G"
     ]
    }
   ],
   "source": [
    "!yarn add @langchain/community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e1a30a-5d49-4aed-b656-a5ce69c99a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (24.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045cb64-9e6c-4fc7-8fcf-322316724ab8",
   "metadata": {},
   "source": [
    "We first need to install all the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832659a6-399c-4056-8e44-a197bff2cfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (2024.4.28)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (4.66.4)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers[torch]) (0.30.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.40.2)\n",
      "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.30.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install 'transformers[torch]'\n",
    "!pip3 install transformers accelerate\n",
    "!pip3 install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c56bb-b0e3-48e5-ae10-7836f36ec4d1",
   "metadata": {},
   "source": [
    "**Restart kernel after installation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c274e5a-731d-4b95-9d24-95224bbb8231",
   "metadata": {},
   "source": [
    "We will then import all the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd10ae-7145-4178-9c24-1f87c61bb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eada17-310b-48bf-8d60-41517057a9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datasets import Dataset,DatasetDict, load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad59674-4efb-44da-9ab4-c96ed14c6d1b",
   "metadata": {},
   "source": [
    "We reformatted the data set now so that we can use a standard load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f206ed-f235-449c-83f0-459836e32738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load_dataset(\"json\", data_files=\"train1.json\", field=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158fbfe3-fc10-4909-abf9-f8b5604aef73",
   "metadata": {},
   "source": [
    "lets just display the dataset to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac31ed-b930-4795-b602-8ca590714df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee92cc2-0b96-4f63-a18c-353ce055215d",
   "metadata": {},
   "source": [
    "Great, lest split it up, and create validation and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dae960-c217-469d-9d3f-8d25b88fa5f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_datasets = data[\"train\"].train_test_split(train_size=0.9, seed=20)\n",
    "split_datasets[\"validation\"] = split_datasets.pop(\"test\")\n",
    "split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399a79b-c39b-45ba-805c-0db5b00eeabd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_datasets[\"train\"][1][\"translation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7567b-b023-431a-afda-9368c52479e3",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787993a7-e00c-42a0-9244-62098beb70ff",
   "metadata": {},
   "source": [
    "Import a tokenizer to convert all our inputs and targets\n",
    "\n",
    "TOKENs in compiler and LLM/Transformers have different meanings. Tokenisation here refer to the creation of a numerical value for the input tokens, a vector that can be used by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a9705-fe51-40e9-a189-b086d23dc810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508a59f-01c1-43b0-a94a-cd782de35856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"meta-llama/CodeLlama-7b-hf\" # Replace this with your desired model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\", use_auth_token=True, force_download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35668556-8d22-481f-9c26-c17263c158c9",
   "metadata": {},
   "source": [
    "Note because we merged the dataset, we can actually use the same dataset for both source and target.\n",
    "The most interesting thing here is the tokenizer, a hugging face function, that produces the attention_mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ff9d5-9e08-4360-978d-1304bb2c8e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pli_sentence = split_datasets[\"train\"][1][\"translation\"][\"pli\"]\n",
    "ktl_sentence = split_datasets[\"train\"][1][\"translation\"][\"ktl\"]\n",
    "\n",
    "inputs = tokenizer(pli_sentence, return_tensors=\"pt\")\n",
    "targets = tokenizer(ktl_sentence, return_tensors=\"pt\")\n",
    "inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c0ed3-5aa5-4575-83fa-b8311882a964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wrong_targets = tokenizer(ktl_sentence)\n",
    "print(tokenizer.convert_ids_to_tokens(wrong_targets[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c8139c-4094-4cbc-9dca-81893f0f7aef",
   "metadata": {},
   "source": [
    "A quick function to clean up the input sequence and set the model up to accept the input sequence\n",
    "\n",
    "overflowing_tokens and num_truncated tokens are things like whitespace, and start of sequence/end of sequence etc.\n",
    "\n",
    "This model expects the inputs to be named \"labels\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745afd2-1614-4663-83b7-47bd4aa82b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 64\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"pli\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"ktl\"] for ex in examples[\"translation\"]]\n",
    "    \n",
    "    # Tokenize inputs and targets separately\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, truncation=True, padding=True)\n",
    "    model_targets = tokenizer(targets, max_length=max_length, truncation=True, padding=True)\n",
    "    \n",
    "    # Remove unnecessary keys from model_inputs\n",
    "    model_inputs.pop(\"overflowing_tokens\", None)\n",
    "    model_inputs.pop(\"num_truncated_tokens\", None)\n",
    "    \n",
    "    # Add targets to model_inputs\n",
    "    model_inputs[\"labels\"] = model_targets[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ed485-c5f7-4680-9c67-f7ddc3aafb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5cfbb-a1c4-4aef-b15e-1009a9a118d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = split_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3285baca-5cab-4e3f-9391-694e565deb5f",
   "metadata": {},
   "source": [
    "## Fine-tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816d7b2-61be-44af-9362-4293efd98da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07cf00-c66f-4f55-be7d-cea8d6260f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint, force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496ec7d-aaee-4613-875b-74edeed9b420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf4f43-8a7f-4ad7-974b-584527cafc3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d62c5-3e9c-41a1-9eb1-c5dd603d626e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82cf52-56be-4ab7-9f04-2ae452904de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"no\",  # No evaluation during training\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=150,\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03f6d98-ec8c-4d3d-8787-b227aa42cae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=None,  # Assuming no evaluation dataset\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b384b-b40b-4e2a-b979-647d0c68c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable wandb\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136e02f-d8a2-4177-9699-dfcd2f4f8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b33378-a082-4767-8057-97d5ffab8139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
