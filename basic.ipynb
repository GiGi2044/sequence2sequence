{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb7a759-0017-4bdb-8459-3838fbfd0af0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045cb64-9e6c-4fc7-8fcf-322316724ab8",
   "metadata": {},
   "source": [
    "We first need to install all the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0367d223-fd36-4e31-a1c3-596d658143b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:46:32.280756Z",
     "iopub.status.busy": "2024-04-18T09:46:32.276989Z",
     "iopub.status.idle": "2024-04-18T09:47:03.923630Z",
     "shell.execute_reply": "2024-04-18T09:47:03.921083Z",
     "shell.execute_reply.started": "2024-04-18T09:46:32.280756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.9/dist-packages (1.7.1)\n",
      "Requirement already satisfied: torchvision==0.8.2 in /usr/local/lib/python3.9/dist-packages (0.8.2)\n",
      "Requirement already satisfied: torchaudio==0.7.2 in /usr/local/lib/python3.9/dist-packages (0.7.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1) (1.23.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.8.2) (9.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: antlr4-python3-runtime==4.9.2 in /usr/local/lib/python3.9/dist-packages (4.9.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchtext==0.8.1 in /usr/local/lib/python3.9/dist-packages (0.8.1)\n",
      "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (1.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (1.23.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1->torchtext==0.8.1) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchtext==0.8.1) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.8.1) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchtext==0.8.1) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.8.1) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2\n",
    "!pip install antlr4-python3-runtime==4.9.2\n",
    "!pip install torchtext==0.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c274e5a-731d-4b95-9d24-95224bbb8231",
   "metadata": {},
   "source": [
    "We will then import all the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768ab7b6-46d2-4ab9-9cde-a61fac12abc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:03.926961Z",
     "iopub.status.busy": "2024-04-18T09:47:03.926358Z",
     "iopub.status.idle": "2024-04-18T09:47:07.720426Z",
     "shell.execute_reply": "2024-04-18T09:47:07.717744Z",
     "shell.execute_reply.started": "2024-04-18T09:47:03.926905Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json\n",
    "from antlr4 import *\n",
    "from pli.PLILexer import PLILexer\n",
    "from pli.PLIParser import PLIParser\n",
    "from pli.PLIVisitor import PLIVisitor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894ad64-a38a-4f5d-9a64-c9f117d1af3d",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d080e-b509-4d02-8f2d-4dad07fffa12",
   "metadata": {},
   "source": [
    "We now have to define our **Transformer** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4760782a-fe8b-4697-bb5f-f8ba4cc2f3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.744996Z",
     "iopub.status.busy": "2024-04-18T09:47:07.743889Z",
     "iopub.status.idle": "2024-04-18T09:47:07.767570Z",
     "shell.execute_reply": "2024-04-18T09:47:07.766144Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.744934Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_size,\n",
    "            src_vocab_size,\n",
    "            trg_vocab_size,\n",
    "            src_pad_idx,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_len,\n",
    "            device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "\n",
    "        # (N, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "                .unsqueeze(1)\n",
    "                .expand(src_seq_length, N)\n",
    "                .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "                .unsqueeze(1)\n",
    "                .expand(trg_seq_length, N)\n",
    "                .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        )\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b5703-7e87-462c-aef8-fec2eb4aea7c",
   "metadata": {},
   "source": [
    "## Specifics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e0931-9ac1-4674-a7e9-2452e5e9ce46",
   "metadata": {},
   "source": [
    "We also make a few specific methods to help and simplify the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e946fe2-a12c-4f5b-aea5-5502b59a4f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.769980Z",
     "iopub.status.busy": "2024-04-18T09:47:07.769542Z",
     "iopub.status.idle": "2024-04-18T09:47:07.790567Z",
     "shell.execute_reply": "2024-04-18T09:47:07.788513Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.769941Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_eos(witheos):\n",
    "    noeos = []\n",
    "    for w in witheos:\n",
    "        if w != '<eos>':\n",
    "            noeos.append(w)\n",
    "    return \" \".join(noeos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8b18c9-d1fc-4ac5-bd6d-8a015fb150f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.800750Z",
     "iopub.status.busy": "2024-04-18T09:47:07.800134Z",
     "iopub.status.idle": "2024-04-18T09:47:07.813284Z",
     "shell.execute_reply": "2024-04-18T09:47:07.811278Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.800653Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68336679-ad7d-4d0a-b5b6-c3dcfe15d5d6",
   "metadata": {},
   "source": [
    "### Translate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb997f5-2259-470b-983f-1b87ba14f171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.815554Z",
     "iopub.status.busy": "2024-04-18T09:47:07.814896Z",
     "iopub.status.idle": "2024-04-18T09:47:07.835245Z",
     "shell.execute_reply": "2024-04-18T09:47:07.833136Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.815514Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_sequence(sentence, pli, ktl, device, max_length=50):\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.lower() for token in sentence.split()]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "\n",
    "    tokens.insert(0, pli.init_token)\n",
    "    tokens.append(pli.eos_token)\n",
    "\n",
    "    # Iterate  each languae token and convert to an index\n",
    "    text_to_indices = [pli.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [ktl.vocab.stoi[\"<sos>\"]]\n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == ktl.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [ktl.vocab.itos[idx] for idx in outputs]\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d351dbc7-2e20-45f8-b8f7-4f46c3430394",
   "metadata": {},
   "source": [
    "### Transpile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10fa7b50-7251-445f-b8c5-a73f494de991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.838296Z",
     "iopub.status.busy": "2024-04-18T09:47:07.837286Z",
     "iopub.status.idle": "2024-04-18T09:47:07.851905Z",
     "shell.execute_reply": "2024-04-18T09:47:07.849586Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.838253Z"
    }
   },
   "outputs": [],
   "source": [
    "def transpile_sequence(translated, level):\n",
    "    tokens = translated[\"code\"]\n",
    "    data = translated[\"context\"]\n",
    "    lint = []\n",
    "\n",
    "    for t in tokens:\n",
    "        spacer = \"\".rjust(level * 4)\n",
    "        if t == \"{\":\n",
    "            level += 1\n",
    "        elif t == \"}\" and level > 0:\n",
    "            level -= 1\n",
    "            spacer = \"\".rjust(level * 4)\n",
    "\n",
    "        if t != \"<eos>\":\n",
    "            lint.append(spacer + t)\n",
    "\n",
    "    code = \" \".join(lint)\n",
    "    t = Template(code)\n",
    "\n",
    "    return t.render(data), level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29296155-9ca7-40ba-980b-89a88daedf8d",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a21177c-10e0-4e12-8c26-9accfb9050bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.854636Z",
     "iopub.status.busy": "2024-04-18T09:47:07.854066Z",
     "iopub.status.idle": "2024-04-18T09:47:07.868192Z",
     "shell.execute_reply": "2024-04-18T09:47:07.866094Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.854589Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = lambda x: x.split()\n",
    "\n",
    "pli = Field(sequential=True, use_vocab=True, tokenize=tokenizer, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "ktl = Field(sequential=True, use_vocab=True, tokenize=tokenizer, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "fields = {'pli': ('p', pli), 'ktl': ('k', ktl)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232608a9-084b-492b-a902-05585f595b2c",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23e10d6f-db7e-4441-a4b9-3f338c8f837a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.873332Z",
     "iopub.status.busy": "2024-04-18T09:47:07.872823Z",
     "iopub.status.idle": "2024-04-18T09:47:07.887952Z",
     "shell.execute_reply": "2024-04-18T09:47:07.885753Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.873292Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train, test = TabularDataset.splits(\n",
    "    path='data',\n",
    "    train='train.json',\n",
    "    test='test.json',\n",
    "    format='json',\n",
    "    fields=fields\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b91a16-9dd9-4b4a-842f-df9b97b1c8d0",
   "metadata": {},
   "source": [
    "### Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80394ea0-e38b-4d37-886e-3f7d5ba4aed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.894035Z",
     "iopub.status.busy": "2024-04-18T09:47:07.890754Z",
     "iopub.status.idle": "2024-04-18T09:47:07.914183Z",
     "shell.execute_reply": "2024-04-18T09:47:07.911748Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.893965Z"
    }
   },
   "outputs": [],
   "source": [
    "pli.build_vocab(train, max_size=10000, min_freq=1)\n",
    "ktl.build_vocab(train, max_size=10000, min_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406d75e-2163-49e0-bbcd-825121663c71",
   "metadata": {},
   "source": [
    "### define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cca5e90-dd15-42dc-a9eb-747210ce1224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.916545Z",
     "iopub.status.busy": "2024-04-18T09:47:07.915993Z",
     "iopub.status.idle": "2024-04-18T09:47:07.969838Z",
     "shell.execute_reply": "2024-04-18T09:47:07.967904Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.916496Z"
    }
   },
   "outputs": [],
   "source": [
    "# ready to define everything we need for training our Seq2Seq model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"gpu\")\n",
    "\n",
    "load_model = True\n",
    "save_model = True\n",
    "\n",
    "# Model hyperparameters\n",
    "src_vocab_size = len(pli.vocab)\n",
    "trg_vocab_size = len(ktl.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dropout = 0.10\n",
    "max_len = 100\n",
    "forward_expansion = 4\n",
    "src_pad_idx = ktl.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "global level\n",
    "# Training hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "training_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b718d6e1-148a-43d4-b09c-56ab8e6df43e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:07.972519Z",
     "iopub.status.busy": "2024-04-18T09:47:07.971643Z",
     "iopub.status.idle": "2024-04-18T09:47:13.436570Z",
     "shell.execute_reply": "2024-04-18T09:47:13.434450Z",
     "shell.execute_reply.started": "2024-04-18T09:47:07.972233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tensorboard to get nice loss plot\n",
    "writer = SummaryWriter(\"runs/loss_plot\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d8e4c92-8e1b-49dd-84ca-f9c47c7f96af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:47:13.441150Z",
     "iopub.status.busy": "2024-04-18T09:47:13.439408Z",
     "iopub.status.idle": "2024-04-18T09:47:20.125833Z",
     "shell.execute_reply": "2024-04-18T09:47:20.089196Z",
     "shell.execute_reply.started": "2024-04-18T09:47:13.441097Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, test),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.p),\n",
    "    device=device,\n",
    ")\n",
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "pad_idx = ktl.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8022622-c93e-4909-b0e5-89fe3670d331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:53:11.966466Z",
     "iopub.status.busy": "2024-04-18T09:53:11.965887Z",
     "iopub.status.idle": "2024-04-18T09:53:11.974784Z",
     "shell.execute_reply": "2024-04-18T09:53:11.972913Z",
     "shell.execute_reply.started": "2024-04-18T09:53:11.966424Z"
    }
   },
   "outputs": [],
   "source": [
    "global level\n",
    "sys.argv = [\"\", \"-run\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "139d6f2d-c639-48a8-affd-a1af919079d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:53:16.099543Z",
     "iopub.status.busy": "2024-04-18T09:53:16.098766Z",
     "iopub.status.idle": "2024-04-18T09:53:20.258476Z",
     "shell.execute_reply": "2024-04-18T09:53:20.244660Z",
     "shell.execute_reply.started": "2024-04-18T09:53:16.099349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 113\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mpli2kt -train dataset-file to train the transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mpli2kt -run source-file to transpiler the source file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m \u001b[43mtrain_and_run_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [19], line 84\u001b[0m, in \u001b[0;36mtrain_and_run_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m load_checkpoint(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint.pth.tar\u001b[39m\u001b[38;5;124m\"\u001b[39m), model, optimizer)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Lexer setup\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m input_stream \u001b[38;5;241m=\u001b[39m FileStream(\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     85\u001b[0m lexer \u001b[38;5;241m=\u001b[39m PLILexer(input_stream)\n\u001b[1;32m     86\u001b[0m stream \u001b[38;5;241m=\u001b[39m CommonTokenStream(lexer)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # training loop\n",
    "    if sys.argv[1] == \"-train\":\n",
    "        for epoch in range(num_epochs):\n",
    "            model.eval()\n",
    "            # little bit of output to check the progress\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "                sentences = [\n",
    "                    {'pli': ['PROCEDURE', 'MAIN', '{{type0}}', '{{type1}}'],\n",
    "                     'context': {'type0': 'Array', 'type1': 'String'}},\n",
    "                    {'pli': ['DO'], 'context': {}},\n",
    "                    {'pli': ['END'], 'context': {}}\n",
    "                ]\n",
    "                print(f\"Translated example sentence:\")\n",
    "                level = 0\n",
    "                for s in sentences:\n",
    "                    translated = translate_sequence(\n",
    "                        s['pli'], pli, ktl, device, max_length=50\n",
    "                    )\n",
    "                    transpiled, level = transpile_sequence({\n",
    "                        'code': translated,\n",
    "                        'context': s['context']\n",
    "                    }, level)\n",
    "                    print(f\"{transpiled}\")\n",
    "            model.train()\n",
    "            losses = []\n",
    "\n",
    "            for batch_idx, batch in enumerate(train_iterator):\n",
    "                # Get input and targets and get to cuda\n",
    "                inp_data = batch.p.to(device)\n",
    "                target = batch.k.to(device)\n",
    "\n",
    "                # Forward\n",
    "                output = model(inp_data, target[:-1, :])\n",
    "\n",
    "                output = output.reshape(-1, output.shape[2])\n",
    "                target = target[1:].reshape(-1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss = criterion(output, target)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                # Back prop\n",
    "                loss.backward()\n",
    "                # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "                # within a healthy range\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "                # Gradient descent step\n",
    "                optimizer.step()\n",
    "\n",
    "                # plot to tensorboard\n",
    "                writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "                step += 1\n",
    "\n",
    "            mean_loss = sum(losses) / len(losses)\n",
    "            scheduler.step(mean_loss)\n",
    "\n",
    "        if save_model:\n",
    "            checkpoint = {\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            }\n",
    "            save_checkpoint(checkpoint)\n",
    "\n",
    "\n",
    "    elif sys.argv[1] == \"-run\":\n",
    "        load_checkpoint(torch.load(\"checkpoint.pth.tar\"), model, optimizer)\n",
    "        # Lexer setup\n",
    "        input_stream = FileStream(sys.argv[2])\n",
    "        lexer = PLILexer(input_stream)\n",
    "        stream = CommonTokenStream(lexer)\n",
    "\n",
    "        # Parser setup\n",
    "        parser = PLIParser(stream)\n",
    "        tree = parser.program()\n",
    "\n",
    "        # Dataset generation\n",
    "        visitor = PLIVisitor()\n",
    "        statements = visitor.visit(tree)\n",
    "\n",
    "        #for s in statements:\n",
    "        #    print(s)\n",
    "\n",
    "        level = 0\n",
    "        for s in statements:\n",
    "            translated = translate_sequence(\n",
    "                s[\"pli\"], pli, ktl, device, max_length=50\n",
    "            )\n",
    "            transpiled, level = transpile_sequence({\n",
    "                'code': translated,\n",
    "                'context': s['context']\n",
    "            }, level)\n",
    "            print(f\"{transpiled}\")\n",
    "    else:\n",
    "        print(\"usage:\"\n",
    "              \"\\n\\tpli2kt -train dataset-file to train the transformer\"\n",
    "              \"\\n\\tpli2kt -run source-file to transpiler the source file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf7c492b-a3a9-484c-9adb-1115a2cd0415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T10:47:57.605613Z",
     "iopub.status.busy": "2024-04-18T10:47:57.604129Z",
     "iopub.status.idle": "2024-04-18T10:47:57.617819Z",
     "shell.execute_reply": "2024-04-18T10:47:57.615652Z",
     "shell.execute_reply.started": "2024-04-18T10:47:57.605547Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (652464893.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [3], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Factorial: proc options (main);\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pli_code = [\n",
    " Factorial: proc options (main);\n",
    "    dcl (n,result) fixed bin(31);\n",
    "    n  = 5;\n",
    "    result = Compute_factorial(n);\n",
    "\n",
    " end Factorial;\n",
    "  /***********************************************/\n",
    "  /* Subroutine                                  */\n",
    "  /***********************************************/\n",
    "  Compute_factorial: proc (n)  returns (fixed bin(31));\n",
    "     dcl n fixed bin(15);\n",
    "      if n <= 1 then\n",
    "        return(1);\n",
    "\n",
    "     return( n*Compute_factorial(n-1) );\n",
    "\n",
    "  end Compute_factorial;\n",
    "]\n",
    "\n",
    "# Translate PLI to KTL\n",
    "translated_code = translate_sequence(pli_code, pli, ktl, device)\n",
    "transpiled_code, _ = transpile_sequence({'code': translated_code, 'context': {}}, level=0)\n",
    "\n",
    "# Print the translated KTL code\n",
    "print(transpiled_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0153d4-1048-4a95-8016-0c22a7a87fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
